{\Huge \title{Machine Learning}}
\section{Supervised Learning}
\subsection{Classification}
\subsubsection{KNN}
\textbf{K-Nearest-Neighbours} - The euclidean distance between a data point and a series of features is calculated and the majority value of the target variable is taken.

\begin{eqnarray*}
	\textit{distance} = \sqrt{(w_0-w_1)^2+(x_0-x_1)^2+(y_0 - y_1)^2+(z_0 - z_1)^2 ...}
\end{eqnarray*}

\begin{itemize}
	\item A large value of k leads to a less complex model and can lead to \textit{underfitting}
	\item A smaller value of k increases the complexity of the model and can lead to \textit{overfitting}
\end{itemize}

\section{Measuring Model Performance}